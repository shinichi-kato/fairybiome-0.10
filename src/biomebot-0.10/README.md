biomebot-0.10
==================================
チャットボットモジュール

## メカニズム
人の心には複数の「心のパート」が存在し、すべてが並列的に動作しながら発言権は競争的に
調整されている。この挙動を再現するため、本チャットボットはシンプルなチャットボットを
複数 web worker として動作させ、それらの取りまとめを別の web worker が行う構成とし、
前者をpart、後者をcentralと呼ぶ。アプリケーションのAPIはcentralが担当する。

## API
チャットボットモジュールは web worker として設計されており、postMessage()を利用して
メインスレッドのスクリプトと通信する。

### 初期化
投入メッセージ { type: 'init', name }
応答メッセージ { type: 'init', name, state }

スクリプトを予めdbに書き込んでおき、そのnameを指定することでcentralがスクリプトを
読み込む。成功したら類似度行列の計算を行い、結果をdbに書き込むとともにメモリにロードする。
並列処理でcentral内で指定されたpartのweb workerを起動し、それぞれにinitを行う。
すべての初期化に成功したら{state:'ok'}を返す。いずれかで失敗したら{name, state: 'err'}
を返す。

### 再開
投入メッセージ { type: 'resume', name}
応答メッセージ { type: 'resume', name, state }

指定したnameの類似度行列や記憶を読み込み、応答可能な状態にする。

### シャットダウン
投入メッセージ { type: 'shutdown', name }
応答メッセージ { type: 'shutdown', name, state }

### ユーザ発言の発信
投入メッセージ { type: 'user_speech', name, text }

ユーザ発言はすべてのpartとcentralが受け取る。これを受けたpartは内部的な応答メッセージ
{type: 'internal_speech', name, text, score } をポストする。

### チャットボット発言の発信
応答メッセージ { type: 'bot_speech', name, text, state }

centralは{type: 'user_speech'}を受け取ったら受信まち状態になり、すべてのpartから
{type: 'internal_speech'}を受け取るまで待つ、それらのうち最もスコアの高いものを選び
nameには起源となったpartの名前を格納してこのメッセージとしてポストする。

### 環境からの入力
投入メッセージ {type: 'environment', name, text}
ユーザの入退室、季節や時刻、天候などの環境の変化が生じた場合このメッセージを投入する。
textには{env.user_login}、{env.morning}などのタグを用いる。{env.*}

## 会話の動作機序

1. {type: 'init'}または{type: 'resume'}によりチャットボットが起動される

2. ユーザが発言した場合、それを{type: 'user_speech'}として投入する。
このメッセージはすべてのpartが受取り、結果を{type:'internal_speech}としてを投入する。

3. {type: 'environment'}が投入されたらすべてのpartが受取り、結果を{type:'internal_speech'}
として投入する。

4. centralは設定した期間の間{type: 'internal_speech'}を受取り、その中でスコアが
一定以上で最も高いものを{type: 'bot_speech'}として投入する。スコアが高いものが複数あったら両方を
投入する。この「設定した期間」は幅を持って変動し、4.の動作を繰り返す。

5. partは{type: 'bot_speech'}を受信したとき、それのnameが自分と同じであった場合
設定した確率で次回の発言スコアを設定した量増やす。nameが自分と異なっていた場合は
改めて{type: 'internal_speech'}を発行するが、このときのスコアは設定した値に弱める。


## 各workerの概要

### central 

{
    name,       // 識別名
    interval: { // 返答生成の期間
        max,    // 最大(msec)
        min     // 最小(msec)
    },
    minIntensity, // 応答する最小の強度
    parts: [],  // パートの名前のリスト
    stateMachine, // 状態機械名




}
centralはメインスクリプトを読み込んで、パートのweb workerを起動する。
会話ではユーザから入力はpostMessageによりすべてのパートに通知される。centralおよび
各パートは返答をpostMessageで発行し、centralはそれらのうち最も強いものを返答とする。
最も強いものが複数あった場合は両方発言する。

### part

パートは

パートに
#### ログ型
会話ログをスクリプトとし、返答に採用した行の番号を保持する。
次の発言はその行からの距離が近いと類似度のスコアが加味される。

#### 収集型

このパートはユーザ入力から情報を集め、それらが揃ったときに

## 辞書スクリプト

### IN辞書で使うコマンド

#### {tag_name}
チャットボットは名前など特定の記憶を保持する。ユーザ入力中にそれが含まれる場合
{tag_name}に変換され、その後辞書で評価される。

#### {?tag_name}  
例えばユーザがチャットボットに与えたニックネームは{nickname}のように格納される。
IN辞書中に{?nickname}があると、{nickname}が定義されていれば{nickname}に変換され、
定義されていなければ空文字列に変換される。これにより「何かを覚えている場合の動作」
を記述できる

#### {?!tag_name}
{?tag_name}と逆で、{memory_name}が定義されていなければ{memory_name}に変換され、
定義されていれば空文字列に変換される。これにより「何かを覚えていない場合の動作」
を記述できる

### OUT辞書で使うコマンド

#### {+tag_name} 
この文字列が見つかった場合、タグを永続的に記憶

## 機械学習

英語における従来の類似テキスト検出では、スペース区切りされた単語を最小単位と
位置づけ、単語を次元とした1-hotベクターを内部表現として自然言語処理を行った。
日本語の場合は形態素やそれをベースにした分かち書きの結果を最小単位としており、
英単語と比べてより細かい分割が行われている。上述の最小単位を以下ノードと呼ぶ。

チャットボットで返答を生成するには、入力文字列と出力文字列のペアからなる
辞書を用意し、ユーザの発言が辞書の入力文字列と類似していればそれに対応した
出力文字列を返答とする、というのが最もかんたんな方法の一つで、テキストを

「ノードを次元としたベクター」に変換し、ベクター同士のcos類似度を計算すれば
類似したテキストを見つけることができる。

この方法では単語ベースで似たテキストは検出できても違う言葉で意味が似ている
表現は検出できない。目標の単語の周囲の単語の並びを利用するn-gramはこれを
改善できる可能性があり、n-gramを使ったword2vecでは似た単語はベクトルも
似ていることが期待される。そこで、辞書を一つのコーパスと見立ててコーパス内の
類似単語を同じとみなすような処理をすれば、「単語が違っていても似た表現」に
対応できると考えられる。
ここで、日本語の場合、ノードが形態素レベルに分割されていることが精度を
下げる原因となる。例えば「日本語」は「日本/語」と分割される。その場合

1. 複合語を一つのノードに統合する
2. コーパスをword2vecでベクトル化し、k-meansなどのクラスタリング手法で
類似単語をクラスタ化する
3. クラスタに属する語を同じ意味とみなすためタグに置き換える
4. タグに置き換えたテキストでベクターを生成し、cos類似度で類似テキストを
特定する


### 複合語辞書 compounds.json
[
    [代表surface,surfaces...],
    ...
]

### クラスタ辞書 clusters.json
[
    [代表surface, surfaces...]
]


